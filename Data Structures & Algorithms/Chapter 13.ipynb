{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing\n",
    "\n",
    "Key topics include:\n",
    "* Pattern Matching Algorithms\n",
    "* Dynamic Programming\n",
    "* Text Compression & Greedy Search\n",
    "* Tries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages and data\n",
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching Algorithms\n",
    "\n",
    "* In the classic pattern-matching problem, we are given a text string T of length n and a pattern string P of length m, and want to find whether P is a substring of T\n",
    "* In this section, we have 3 algorithms:\n",
    "    * Brute force: The brute-force algorithmic design pattern is a powerful technique for algorithm design when we have something we wish to search for or when we wish to optimize some function; running time of brute-force pattern matching in the worst case is not good\n",
    "    * The Boyer-Moore algorithm: The main idea of the Boyer-Moore algorithm is to improve the running time of the brute-force algorithm by adding two potentially time-saving heuristics. Roughly stated, these heuristics are as follows:\n",
    "        * Looking-Glass Heuristic: When testing a possible placement of P against T, begin the comparisons from the end of P and move backward to the front of P\n",
    "        * Character-Jump Heuristic\n",
    "    * The Knuth-Morris-Pratt algorithm: builds upon the above 2 by removing the following inefficiency - for a certain alignment of the pattern, if we find several matching characters but then detect a mismatch, we ignore all the information gained by the successful comparisons after restarting with the next incremental placement of the pattern\n",
    "        * KMP avoids this waste of information and, in so doing, it achieves a running time of O(n+m), which is asymptotically optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "* Dynamic programming can often be used to take problems that seem to require exponential time and produce polynomial-time algorithms to solve them\n",
    "    * Used primarily for optimization problems, where we wish to find the “best” way of doing something\n",
    "* An example is the Matrix-Chain Product:\n",
    "    * The matrix chain-product problem is to determine the parenthesization of the expression defining the product A that minimizes the total number of scalar multiplications performed\n",
    "    * One way to solve the matrix chain-product problem is to simply enumerate all the possible ways of parenthesizing the expression for A and determine the number of multiplications performed by each one - this brute force method however runs on exponential time\n",
    "    * We can improve the perfomance by splitting the matrix chain product problem into subproblems\n",
    "* Components/ key components of dynamic programming solution:\n",
    "    * Simple subproblems: There has to be some way of repeatedly breaking the global optimization problem into subproblems \n",
    "    * Subproblem Optimization: An optimal solution to the global problem must be a composition of optimal subproblem solutions.\n",
    "    * Subproblem Overlap: Optimal solutions to unrelated subproblems can contain subproblems in common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Compression & The Greedy Method\n",
    "\n",
    "* Text compression is useful in any situation where we wish to reduce bandwidth for digital communications, so as to minimize the time needed to transmit our text. Likewise, text compression is useful for storing large documents more efficiently, so as to allow a fixed-capacity storage device to contain as many documents as possible\n",
    "* An xample discussed in this section is Huffman Code:\n",
    "    * Huffman coding is a lossless data compression algorithm that assigns variable-length codes to input characters, with more frequent characters receiving shorter codes. This results in reduced file sizes, particularly for text files with uneven character distributions\n",
    "    * It works by creating a binary tree where characters are represented as leaf nodes, and the path from the root to a character represents its code\n",
    "* The Greedy Method: Huffman’s algorithm for building an optimal encoding is an example application of an algorithmic design pattern called the greedy method\n",
    "    * This design pattern is applied to optimization problems, where we are trying to construct some structure while minimizing or maximizing some property of that structure\n",
    "    * A greedy method, also known as a greedy algorithm, is a problem-solving approach that makes the best choice at each step, hoping to lead to an overall optimal solution. It focuses on making locally optimal decisions without considering the consequences of those choices for future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tries\n",
    "\n",
    "* A trie (pronounced “try”) is a tree-based data structure for storing strings in order to support fast pattern matching. The main application for tries is in information\n",
    "retrieval (Indeed, the name “trie” comes from the word “retrieval.”)\n",
    "* Tries can be used to perform a special type of pattern matching, called word matching, where we want to determine whether a given pattern matches one of the words of the text exactly\n",
    "    * There is a potential space inefficiency in the standard trie that has prompted the development of the compressed trie, which is also known (for historical reasons) as the Patricia trie\n",
    "* A compressed trie is similar to a standard trie but it ensures that each internal node in the trie has at least two children. It enforces this rule by compressing chains of single-child nodes into individual edges\n",
    "    * The advantage of a compressed trie over a standard trie is that the number of nodes of the compressed trie is proportional to the number of strings and not to their total length\n",
    "* Searching in a compressed trie is not necessarily faster than in a standard tree, since there is still need to compare every character of the desired pattern with the potentially multi-character labels while traversing paths in the trie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics_data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
